{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlating spike trains\n",
    "\n",
    "Recall that our research questions for this data set were:\n",
    "- Does stimulation with a sine wave grating increase functional connectivity between neurons?\n",
    "- If so, are increases in functional connectivity specific to the orientation of the stimulus?\n",
    "\n",
    "We hypothesized that the answer to both questions would be \"yes\". Here we compute functional connectivity (correlation) between each pair of neurons in the data set, to answer these questions.\n",
    "\n",
    "In functional connectivity, we are typically interested in how similar (correlated) the patterns of activity of neurons are over time. That is, if two neurons show increases in spike probabilities at similar times, relative to the presentation of the stimulus, they are said to be more strongly functionally connected than two neurons that do not show similar response patterns. Because the PSTH characterizes the response of a neuron over time, averaged across many trials, these are what we use as input to the functional connectivity analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "We previously talked about  SciPy as the library that provided a function for importing Matlab files. The SciPy library has many useful routines for general-purpose scientific work, including many statistical and machine learning functions. Here we import `scipy.stats` so that we can use its correlation functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "import scipy.io\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sc\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "psth = pd.read_csv('data/array_psth.csv', index_col=['orientation', 'channel'])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute correlation matrix \n",
    "\n",
    "pandas has a `.corr()` method that computes a correlation matrix from a DataFrame. It correlates the *columns*, which is not what we want here, because in `psth`, each *row* is a histogram for a channel. So we chain the `.T` method with `.corr()`, which [**transposes**](https://en.wikipedia.org/wiki/Transpose) the matrix (i.e., turns rows into columns).\n",
    "\n",
    "Below shows the result of doing this, selecting only for the 90 deg orientation condition using `.loc[]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "psth.loc[90].T.corr()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrices with large numbers of values are much easier to make sense of when plotted with colour representing the correlation values, rather than as a matrix of raw numbers. Below we do this, separately for each orientation. The plot on the right, below, is the same correlation matrix as shown above, just in a visual rather than tabular format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# Get levels of orientation from the data. Although we know these are 0 and 90, \n",
    "# and could hard-code these, our code is more robust and adaptable if we get\n",
    "# these from the data itself\n",
    "ortn_levs = psth.index.get_level_values('orientation').unique()\n",
    "\n",
    "fig = plt.figure(figsize=[20, 7])\n",
    "for oidx, ortn in enumerate(ortn_levs):\n",
    "    ax = fig.add_subplot(1, len(ortn_levs), oidx+1)\n",
    "    plt.imshow(psth.loc[ortn].T.corr(), clim=(-1, 1), cmap='viridis') \n",
    "    plt.colorbar()\n",
    "    ax.invert_yaxis()\n",
    "    plt.title(str(int(ortn)) + ' deg')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Channel')\n",
    "    \n",
    "plt.show()\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove noisy channels\n",
    "\n",
    "The authors who provided the data note that some of the channels were noisy. This may be due to technical issues in recording, or other issues. Regardless, We want to exclude these as their data do not appear to represent real neuronal activity. We first define a list of the noisy channels (provided by Nylen and Wallisch):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "noisy = [7, 16, 32, 37, 39, 41, 43, 45, 47, 48, 51, 52, 54, 94, 95]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the channels are stored in one of the indexes of the `psth` DataFrame, we use the code below to select and remove the noisy channels. This is similar to code you've seen before, for selecting rows of a pandas DataFrame, using the `~` operator to take the inverse of whatever we select (i.e., \"keep the channels that are *not* in `noisy`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "psth = psth[~psth.index.get_level_values('channel').isin(noisy)]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we re-compute and plot the correlation matrices. These look very similar to the ones above, but if you look at the *x* and *y* axis ranges you can see there are fewer channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# Get levels of orientation from the data. Although we know these are 0 and 90, \n",
    "# and could hard-code these, our code is more robust and adaptable if we get\n",
    "# these from the data itself\n",
    "ortn_levs = psth.index.get_level_values('orientation').unique()\n",
    "\n",
    "fig = plt.figure(figsize=[20, 7])\n",
    "for oidx, ortn in enumerate(ortn_levs):\n",
    "    ax = fig.add_subplot(1, len(ortn_levs), oidx+1)\n",
    "    plt.imshow(psth.loc[ortn].T.corr(), clim=(-1, 1), cmap='viridis') \n",
    "    plt.colorbar()\n",
    "    ax.invert_yaxis()\n",
    "    plt.title(str(int(ortn)) + ' deg')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Channel')\n",
    "    \n",
    "plt.show()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict time range\n",
    "\n",
    "Finally, recall that the research question refers specifically to functional connectivity when stimuli are presented. So we should restrict the data we use to compute our correlation matrices, to the time points when the stimuli were presented. As noted when we introduced this experiment, each trial was 2150 ms long, but the first 150 ms was a fixation period, followed by a 2000 ms stimulus presentation. So we want to remove the first 150 ms of data.\n",
    "\n",
    "Since our data are already in the form of histograms, that were computed over bins (ranges of time), we need to know how wide (i.e., how many milliseconds long) each bin is, so that we can figure out how many bins comprise the first 150 ms of the trials.\n",
    "\n",
    "We know that the total length of the trials was 2150 ms, and we can use the number of columns in the `psth` DataFrame to derive the value for the total number of bins in each PSTH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "2150 / psth.shape[1]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is not an even number, we can round it and save it as the variable `bin_width`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "bin_width = round(2150 / psth.shape[1])\n",
    "print(bin_width)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `bin_width` to determine how many bins comprise the 150 ms baseline period:\n",
    "~~~python\n",
    "baseline = round(150 / bin_width)\n",
    "print(baseline)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can use `.iloc[]` to select only the column numbers (bins) after the baseline:\n",
    "~~~python\n",
    "psth_stim = psth.iloc[:, baseline:]\n",
    "psth_stim\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "psth_stim = psth.iloc[:, baseline:]\n",
    "\n",
    "fig = plt.figure(figsize=[20, 7])\n",
    "for oidx, ortn in enumerate(ortn_levs):\n",
    "    ax = fig.add_subplot(1, len(ortn_levs), oidx+1)\n",
    "    plt.imshow(psth_stim.loc[ortn].T.corr(), clim=(-1, 1), cmap='viridis') \n",
    "    plt.colorbar()\n",
    "    ax.invert_yaxis()\n",
    "    plt.title(str(int(ortn)) + ' deg')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Channel')\n",
    "    \n",
    "plt.show()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
